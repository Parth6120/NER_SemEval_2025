{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67e40572",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ptlpa\\anaconda3\\envs\\comet\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# General imports\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Import the comet module for the evaluation\n",
    "from comet import download_model, load_from_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3765eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMET_MODEL_NAME = \"Unbabel/wmt22-comet-da\"\n",
    "SYSTEM_NAME = \"gpt-4o-2024-08-06\"\n",
    "SOURCE_LANGUAGE = \"en_US\"\n",
    "TARGET_LANGUAGE = \"fr_FR\"\n",
    "DATA_DIR = \"../data\"\n",
    "SPLIT = \"validation\"\n",
    "NUM_GPUS = 1\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# The path to the references is formatted as follows:\n",
    "# data/references/{split}/{target_language}.jsonl\n",
    "PATH_TO_REFERENCES = os.path.join(\n",
    "    DATA_DIR,\n",
    "    \"references\",\n",
    "    SPLIT,\n",
    "    f\"{TARGET_LANGUAGE}.jsonl\",\n",
    ")\n",
    "\n",
    "# The path to the predictions is formatted as follows:\n",
    "# data/predictions/{system_name}/{split}/{target_language}.jsonl\n",
    "PATH_TO_PREDICTIONS = os.path.join(\n",
    "    DATA_DIR,\n",
    "    \"predictions\",\n",
    "    SYSTEM_NAME,\n",
    "    SPLIT,\n",
    "    f\"{TARGET_LANGUAGE}.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d711275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 724 references from ../data\\references\\validation\\fr_FR.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Load the references\n",
    "references = {}\n",
    "\n",
    "with open(PATH_TO_REFERENCES, \"r\") as f:\n",
    "\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        references[data[\"id\"]] = data\n",
    "\n",
    "print(f\"Loaded {len(references)} references from {PATH_TO_REFERENCES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e1aaa2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 724 predictions from ../data\\predictions\\gpt-4o-2024-08-06\\validation\\fr_FR.jsonl\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "\n",
    "with open(PATH_TO_PREDICTIONS, \"r\") as f:\n",
    "\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        predictions[data[\"id\"]] = data\n",
    "\n",
    "print(f\"Loaded {len(predictions)} predictions from {PATH_TO_PREDICTIONS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0623d5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All references have a corresponding prediction\n"
     ]
    }
   ],
   "source": [
    "# Get all those references that have a corresponding prediction\n",
    "ids = set(references.keys()) & set(predictions.keys())\n",
    "num_missing_predictions = len(references) - len(ids)\n",
    "\n",
    "if num_missing_predictions > 0:\n",
    "    print(f\"Missing predictions for {num_missing_predictions} references\")\n",
    "else:\n",
    "    print(\"All references have a corresponding prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1611be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 1316 instances\n"
     ]
    }
   ],
   "source": [
    "instance_ids = {}\n",
    "instances = []\n",
    "current_index = 0\n",
    "\n",
    "for id in sorted(list(ids)):\n",
    "    reference = references[id]\n",
    "    prediction = predictions[id]\n",
    "\n",
    "    for target in reference[\"targets\"]:\n",
    "        instances.append(\n",
    "            {\n",
    "                \"src\": reference[\"source\"],\n",
    "                \"ref\": target[\"translation\"],\n",
    "                \"mt\": prediction[\"prediction\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    instance_ids[id] = [current_index, current_index + len(reference[\"targets\"])]\n",
    "    current_index += len(reference[\"targets\"])\n",
    "\n",
    "print(f\"Created {len(instances)} instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b4f8258",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 23.09it/s]\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\ptlpa\\.cache\\huggingface\\hub\\models--Unbabel--wmt22-comet-da\\snapshots\\2760a223ac957f30acfb18c8aa649b01cf1d75f2\\checkpoints\\model.ckpt`\n",
      "c:\\Users\\ptlpa\\anaconda3\\envs\\comet\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ptlpa\\.cache\\huggingface\\hub\\models--xlm-roberta-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Encoder model frozen.\n",
      "c:\\Users\\ptlpa\\anaconda3\\envs\\comet\\lib\\site-packages\\pytorch_lightning\\core\\saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n"
     ]
    }
   ],
   "source": [
    "# Download the model\n",
    "model_path = download_model(COMET_MODEL_NAME)\n",
    "\n",
    "# Load the model\n",
    "model = load_from_checkpoint(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed336f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0:   0%|          | 0/42 [00:00<?, ?it/s]c:\\Users\\ptlpa\\anaconda3\\envs\\comet\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [01:19<00:00,  1.90s/it]\n"
     ]
    }
   ],
   "source": [
    "# Compute the scores\n",
    "outputs = model.predict(instances, batch_size=BATCH_SIZE, gpus=NUM_GPUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "550852a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average COMET score: 89.13\n"
     ]
    }
   ],
   "source": [
    "# Extract the scores\n",
    "scores = outputs.scores\n",
    "max_scores = []\n",
    "\n",
    "for id, indices in instance_ids.items():\n",
    "    # Get the max score for each reference\n",
    "    max_score = max(scores[indices[0] : indices[1]])\n",
    "    max_scores.append(max_score)\n",
    "\n",
    "# Compute the average score while taking into account the missing predictions (which are considered as 0)\n",
    "system_score = sum(max_scores) / (len(max_scores) + num_missing_predictions)\n",
    "\n",
    "print(f\"Average COMET score: {100.*system_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5ff32b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8763466791949012"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.system_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9328d056",
   "metadata": {},
   "source": [
    "# finetuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a801dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMET_MODEL_NAME = \"Unbabel/wmt22-comet-da\"\n",
    "SYSTEM_NAME = \"finetuned_placeholder_mt\"\n",
    "SOURCE_LANGUAGE = \"en_US\"\n",
    "TARGET_LANGUAGE = \"fr_FR\"\n",
    "DATA_DIR = \"../data\"\n",
    "SPLIT = \"validation\"\n",
    "NUM_GPUS = 1\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# The path to the references is formatted as follows:\n",
    "# data/references/{split}/{target_language}.jsonl\n",
    "PATH_TO_REFERENCES = os.path.join(\n",
    "    DATA_DIR,\n",
    "    \"references\",\n",
    "    SPLIT,\n",
    "    f\"{TARGET_LANGUAGE}.jsonl\",\n",
    ")\n",
    "\n",
    "# The path to the predictions is formatted as follows:\n",
    "# data/predictions/{system_name}/{split}/{target_language}.jsonl\n",
    "PATH_TO_PREDICTIONS = os.path.join(\n",
    "    DATA_DIR,\n",
    "    \"predictions\",\n",
    "    SYSTEM_NAME,\n",
    "    SPLIT,\n",
    "    f\"{TARGET_LANGUAGE}.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9566276b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 724 references from ../data\\references\\validation\\fr_FR.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Load the references\n",
    "references = {}\n",
    "\n",
    "with open(PATH_TO_REFERENCES, \"r\") as f:\n",
    "\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        references[data[\"id\"]] = data\n",
    "\n",
    "print(f\"Loaded {len(references)} references from {PATH_TO_REFERENCES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20b7fb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 724 predictions from ../data\\predictions\\finetuned_placeholder_mt\\validation\\fr_FR.jsonl\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "\n",
    "with open(PATH_TO_PREDICTIONS, \"r\") as f:\n",
    "\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        predictions[data[\"id\"]] = data\n",
    "\n",
    "print(f\"Loaded {len(predictions)} predictions from {PATH_TO_PREDICTIONS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fd32c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All references have a corresponding prediction\n"
     ]
    }
   ],
   "source": [
    "# Get all those references that have a corresponding prediction\n",
    "ids = set(references.keys()) & set(predictions.keys())\n",
    "num_missing_predictions = len(references) - len(ids)\n",
    "\n",
    "if num_missing_predictions > 0:\n",
    "    print(f\"Missing predictions for {num_missing_predictions} references\")\n",
    "else:\n",
    "    print(\"All references have a corresponding prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c891e29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 1316 instances\n"
     ]
    }
   ],
   "source": [
    "instance_ids = {}\n",
    "instances = []\n",
    "current_index = 0\n",
    "\n",
    "for id in sorted(list(ids)):\n",
    "    reference = references[id]\n",
    "    prediction = predictions[id]\n",
    "\n",
    "    for target in reference[\"targets\"]:\n",
    "        instances.append(\n",
    "            {\n",
    "                \"src\": reference[\"source\"],\n",
    "                \"ref\": target[\"translation\"],\n",
    "                \"mt\": prediction[\"prediction\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    instance_ids[id] = [current_index, current_index + len(reference[\"targets\"])]\n",
    "    current_index += len(reference[\"targets\"])\n",
    "\n",
    "print(f\"Created {len(instances)} instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08fa403a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<?, ?it/s]\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\ptlpa\\.cache\\huggingface\\hub\\models--Unbabel--wmt22-comet-da\\snapshots\\2760a223ac957f30acfb18c8aa649b01cf1d75f2\\checkpoints\\model.ckpt`\n",
      "Encoder model frozen.\n",
      "c:\\Users\\ptlpa\\anaconda3\\envs\\comet\\lib\\site-packages\\pytorch_lightning\\core\\saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n"
     ]
    }
   ],
   "source": [
    "# Download the model\n",
    "model_path = download_model(COMET_MODEL_NAME)\n",
    "\n",
    "# Load the model\n",
    "model = load_from_checkpoint(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ade71e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0:   0%|          | 0/42 [00:00<?, ?it/s]c:\\Users\\ptlpa\\anaconda3\\envs\\comet\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [01:17<00:00,  1.84s/it]\n"
     ]
    }
   ],
   "source": [
    "# Compute the scores\n",
    "outputs = model.predict(instances, batch_size=BATCH_SIZE, gpus=NUM_GPUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "900287b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average COMET score: 84.15\n"
     ]
    }
   ],
   "source": [
    "# Extract the scores\n",
    "scores = outputs.scores\n",
    "max_scores = []\n",
    "\n",
    "for id, indices in instance_ids.items():\n",
    "    # Get the max score for each reference\n",
    "    max_score = max(scores[indices[0] : indices[1]])\n",
    "    max_scores.append(max_score)\n",
    "\n",
    "# Compute the average score while taking into account the missing predictions (which are considered as 0)\n",
    "system_score = sum(max_scores) / (len(max_scores) + num_missing_predictions)\n",
    "\n",
    "print(f\"Average COMET score: {100.*system_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35b61510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8252155175687332"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.system_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e46bba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
